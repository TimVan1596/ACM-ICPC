import os

import tensorflow as tf
from tensorflow import keras
from keras import layers

os.environ['TF_CPP_MIN_LOG_LEVEL'] = "1"

if __name__ == '__main__':
    ### 4.5 å¼ é‡çš„å…¸å‹åº”ç”¨
    ##### 4.5.1 æ ‡é‡
    ##### 4.5.2 å‘é‡
    ##### 4.5.3 çŸ©é˜µ
    ##### 4.5.4 ä¸‰ç»´å¼ é‡
    ##### 4.5.5 å››ç»´å¼ é‡

    ##### 4.5.1 æ ‡é‡
    # æ˜¯ä¸€ä¸ªç®€å•çš„æ•°å­—ï¼Œç»´åº¦æ•°ä¸º; 0ï¼Œshape; ä¸º[]
    # æ¨¡æ‹ŸMSEè¯¯å·®è®¡ç®—
    out = tf.random.uniform([4, 10])
    y = tf.constant([2, 3, 2, 0])
    y = tf.one_hot(y, depth=10)
    loss = tf.keras.losses.mse(y, out)
    loss = tf.reduce_mean(loss)
    # print(loss)

    ##### 4.5.2 å‘é‡
    ##### 4.5.3 çŸ©é˜µ
    ##### 4.5.4 ä¸‰ç»´å¼ é‡
    # ä¸‰ç»´çš„å¼ é‡ä¸€ä¸ªå…¸å‹åº”ç”¨æ˜¯è¡¨ç¤ºåºåˆ—ä¿¡å·ï¼Œå®ƒçš„æ ¼å¼æ˜¯; ğ‘¿ = [ğ‘, sequence len, feature len];
    # å…¶ä¸­ğ‘è¡¨ç¤ºåºåˆ—ä¿¡å·çš„æ•°é‡ï¼Œsequence; len; è¡¨ç¤ºåºåˆ—ä¿¡å·åœ¨æ—¶é—´ç»´åº¦ä¸Šçš„é‡‡æ ·ç‚¹æ•°æˆ–æ­¥æ•°ï¼Œ feature;
    # len; è¡¨ç¤ºæ¯ä¸ªç‚¹çš„ç‰¹å¾é•¿åº¦ã€‚

    # num_words=å•è¯æŒ‰ç…§å®ƒä»¬å‡ºç°çš„é¢‘ç‡ï¼ˆåœ¨è®­ç»ƒé›†ä¸­ï¼‰è¿›è¡Œæ’åºï¼Œå¹¶ä¸”åªä¿ç•™æœ€å¸¸è§çš„å•è¯ã€‚
    # (x_train, y_train), (x_test, y_test) \
    #     = keras.datasets.imdb.load_data(num_words=10000)
    # print(x_train.shape)
    # print(y_train.shape)
    # x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=80)
    # print(x_train.shape)
    # embedding = layers.Embedding(10000, 100)
    # out = embedding(x_train)
    # shape; å˜ä¸º[25000, 80, 100]
    # å…¶ä¸­25000è¡¨ç¤ºå¥å­ä¸ªæ•°ï¼Œ80è¡¨ç¤ºæ¯ä¸ªå¥å­å…±80ä¸ªå•è¯,å…¶ä¸­ 100 è¡¨ç¤ºæ¯ä¸ªå•è¯ç¼–ç ä¸ºé•¿åº¦æ˜¯ 100 çš„å‘é‡
    # print(out.shape)
    ##### 4.5.5 å››ç»´å¼ é‡
    # [ğ‘, â„,, ğ‘]å…¶ä¸­ğ‘è¡¨ç¤ºè¾“å…¥æ ·æœ¬çš„æ•°é‡ï¼Œâ„ / åˆ†åˆ«è¡¨ç¤ºç‰¹å¾å›¾çš„é«˜ / å®½ï¼Œğ‘è¡¨ç¤ºç‰¹å¾å›¾çš„é€šé“æ•°
    # æ¨¡æ‹Ÿåˆ›å»º32*32çš„å½©è‰²å›¾ç‰‡è¾“å…¥ï¼Œä¸ªæ•°ä¸º4
    x = tf.random.normal([4, 32, 32, 3])
    # åˆ›å»ºå·ç§¯ç¥ç»ç½‘ç»œ
    layer = layers.Conv2D(16, kernel_size=3)
    out = layer(x)
    print(out.shape)
    print(layer.kernel.shape)
