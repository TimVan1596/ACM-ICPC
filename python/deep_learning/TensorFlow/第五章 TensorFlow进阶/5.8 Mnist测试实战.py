import os

import tensorflow as tf
import keras.datasets as datasets
import matplotlib.pyplot as plt

os.environ['TF_CPP_MIN_LOG_LEVEL'] = "2"
print(tf.__version__)

# pyplotæ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False


# è·å–æ•°æ®é›†
def load_data(batch_size=200):
    # 1ã€è·å– MNIST æ•°æ®é›†
    (x, y), (_, _) = datasets.mnist.load_data()
    # 2ã€æ•°æ®é¢„å¤„ç†ï¼šxè½¬ä¸ºæµ®ç‚¹æ•°ï¼Œå¹¶ç¼©æ”¾åˆ°-1~1ï¼Œæœ€åæ”¹å˜è§†å›¾
    #               yè½¬ä¸ºæ•´æ•° ï¼Œå¹¶è½¬ä¸ºç‹¬çƒ­ç¼–ç 
    # x = (60000, 28, 28) y=(60000,)
    x = tf.convert_to_tensor(x, dtype=tf.float32) / 255
    x = tf.reshape(x, (-1, 28 * 28))
    y = tf.convert_to_tensor(y, dtype=tf.int32)
    y = tf.one_hot(y, depth=10)
    # 3ã€æ„å»ºæ•°æ®é›†å¯¹è±¡ï¼Œè¿›è¡Œmini-batchåˆ†ç»„
    train_dataset = tf.data.Dataset.from_tensor_slices((x, y))
    # æ‰¹é‡è®­ç»ƒ
    train_dataset = train_dataset.batch(batch_size=200)
    return train_dataset


# åˆå§‹åŒ–å‚æ•°
def init_parameters():
    # æ¯å±‚çš„å¼ é‡éƒ½éœ€è¦è¢«ä¼˜åŒ–ï¼Œæ•…ä½¿ç”¨Variableç±»å‹
    # å¹¶ä½¿ç”¨æˆªæ–­çš„æ­£å¤ªåˆ†å¸ƒåˆå§‹åŒ–æƒå€¼å¼ é‡
    # åç½®å‘é‡åˆå§‹åŒ–ä¸º 0 å³å¯
    w1 = tf.Variable(tf.random.truncated_normal([784, 256], stddev=0.1))
    b1 = tf.Variable(tf.zeros(256))
    w2 = tf.Variable(tf.random.truncated_normal([256, 128], stddev=0.1))
    b2 = tf.Variable(tf.zeros(128))
    w3 = tf.Variable(tf.random.truncated_normal([128, 10], stddev=0.1))
    b3 = tf.Variable(tf.zeros(10))
    return w1, b1, w2, b2, w3, b3


# epochè¿›è¡Œè®­ç»ƒ
# 1 epoch=ä¸€ä»£=åªæ˜¯ä¸€æ¬¡éå†äº†è®­ç»ƒé›†
def train_epoch(epoch, train_dataset, param, lr=0.001):
    w1, b1, w2, b2, w3, b3 = param[0], param[1], param[2], param[3], param[4], param[5]

    # æ€»å…±300ä¸ªstepï¼Œæ¯ä¸ªstepæœ‰200ä¸ªæ•°æ®
    # 300*200 = 600000 =  MNISTæ•°æ®é›†æ•°é‡
    for step, (x, y) in enumerate(train_dataset):
        # x.shape=(200, 784)  y.shape=(200, 10)
        with tf.GradientTape() as tape:
            # ä¸‰å±‚ç»“æ„ä¸º 784*256,256*128,128*10
            # ç¬¬ä¸€å±‚ (200, 784)*(784, 256)+(200,256) = (200,256)
            h1 = x @ w1 + b1
            h1 = tf.nn.relu(h1)
            # ç¬¬äºŒå±‚ (200,256)*(256, 128)+(200,128) = (200,128)
            h2 = h1 @ w2 + b2
            h2 = tf.nn.relu(h2)
            # è¾“å‡ºå±‚ (200,128)*(128, 10)+(200,10) = (200,10)
            h3 = h2 @ w3 + b3
            out = tf.nn.relu(h3)
            # è®¡ç®—å‡æ–¹å·® mse = mean(sum(y-out)^2)
            loss = tf.square(y - out)
            loss = tf.reduce_mean(loss)
            grads = tape.gradient(loss, [w1, b1, w2, b2, w3, b3])
        # æ¢¯åº¦æ›´æ–°ï¼ŒåŸåœ°æ›´æ–°
        w1.assign_sub(grads[0] * lr)
        b1.assign_sub(grads[1] * lr)
        w2.assign_sub(grads[2] * lr)
        b2.assign_sub(grads[3] * lr)
        w3.assign_sub(grads[4] * lr)
        b3.assign_sub(grads[5] * lr)
        if step % 200 == 0:
            tips = "[debug]:epoch={0},step={1} => loss:{2}" \
                .format(epoch, step, loss.numpy())
            print(tips)
    return loss.numpy()


def train(epochs):
    losses = []
    # 1ã€è·å–æ•°æ®é›†
    train_dataset = load_data(batch_size=200)
    # 2ã€åˆå§‹åŒ–å‚æ•°
    (w1, b1, w2, b2, w3, b3) = init_parameters()
    param = (w1, b1, w2, b2, w3, b3)
    # 3ã€epochè¿›è¡Œè®­ç»ƒ
    for epoch in range(epochs):
        loss = train_epoch(epoch, train_dataset, param, lr=0.001)
        losses.append(loss)
    x = range(0, epochs)
    # ç»˜åˆ¶æ›²çº¿
    plt.plot(x, losses, color='orange',
             marker='s', label='è®­ç»ƒ')
    plt.xlabel('Epoch')
    plt.ylabel('MSE')
    plt.legend()
    plt.savefig('MNISTæ•°æ®é›†çš„å‰å‘ä¼ æ’­è®­ç»ƒè¯¯å·®æ›²çº¿.jpg')
    plt.show()
    plt.close()


# åˆ¤æ–­ä¸¤ä¸ªtensorçš„å€¼æ˜¯å¦ç›¸ç­‰
def tensor_equal(a, b):
    # åˆ¤æ–­ç±»å‹æ˜¯å¦å‡ä¸ºtensor
    if type(a) != type(b):
        return False
    if isinstance(a, type(tf.constant([]))) is not True:
        if isinstance(a, type(tf.Variable([]))) is not True:
            return False
    # åˆ¤æ–­å½¢çŠ¶ç›¸ç­‰
    if a.shape != b.shape:
        return False
    # é€å€¼å¯¹æ¯”åè‹¥æœ‰Falseåˆ™ä¸ç›¸ç­‰
    if not tf.reduce_min(tf.cast(a == b, dtype=tf.int32)):
        return False
    return True


if __name__ == '__main__':
    # ### 5.8 MNIST æµ‹è¯•å®æˆ˜
    # ã€€ä¸Šä¸€èŠ‚å‰å‘ä¼ æ’­å’Œæ•°æ®é›†çš„åŠ è½½æ­¥éª¤ï¼š
    # 1ã€è·å–æ•°æ®é›†
    # 2ã€æ•°æ®é›†åˆ†æˆmini-batch
    # 3ã€æŒ‰ç…§epochè¿›è¡Œæ›´æ–°
    # 4ã€ä¸‰å±‚ç¥ç»ç½‘ç»œ
    train(5)

    # åˆ†ç±»ä»»åŠ¡æµ‹è¯•éƒ¨åˆ†é€»è¾‘ï¼š
    # 1ã€ä¼ å…¥å‚æ•°ï¼ˆw1ï¼Œb1ï¼Œw2ï¼Œb2ï¼Œw3ï¼Œb3ï¼‰
    # 2ã€è¿›è¡Œè®­ç»ƒï¼Œè·å–æœ€å¤§ä¸‹æ ‡
    # 3ã€ç»“æœè½¬ä¸º0å’Œ1ï¼Œç»Ÿè®¡ä¸º1çš„ä¸ªæ•°
    # 4ã€è®¡ç®—å‡†ç¡®ç‡ACCï¼Œå¹¶é€šè¿‡pltæ‰“å°

    # å‰é¢å·²ç»ä»‹ç»å¹¶å®ç°äº†å‰å‘ä¼ æ’­å’Œæ•°æ®é›†çš„åŠ è½½éƒ¨åˆ†ã€‚ç°åœ¨æˆ‘ä»¬æ¥å®Œæˆå‰©ä¸‹çš„åˆ†ç±»ä»»åŠ¡é€»è¾‘ã€‚
    #
    # 1. åœ¨è®­ç»ƒçš„è¿‡ç¨‹ä¸­ï¼Œé€šè¿‡é—´éš”æ•°ä¸ª Step åæ‰“å°è¯¯å·®æ•°æ®ï¼Œå¯ä»¥æœ‰æ•ˆç›‘ç£æ¨¡å‹çš„è®­ç»ƒè¿›åº¦
    # 2. åœ¨è‹¥å¹²ä¸ª Step æˆ–è€…è‹¥å¹²ä¸ª Epoch è®­ç»ƒåï¼Œå¯ä»¥è¿›è¡Œä¸€æ¬¡æµ‹è¯•(éªŒè¯)ï¼Œä»¥è·å¾—æ¨¡å‹çš„å½“å‰æ€§èƒ½

    # ç°åœ¨æˆ‘ä»¬æ¥åˆ©ç”¨å­¦ä¹ åˆ°çš„ TensorFlow å¼ é‡æ“ä½œå‡½æ•°ï¼Œå®Œæˆå‡†ç¡®åº¦çš„è®¡ç®—å®æˆ˜
    #
    # 1. å…ˆè€ƒè™‘ä¸€ä¸ª Batch çš„æ ·æœ¬ xï¼Œé€šè¿‡å‰å‘è®¡ç®—å¯ä»¥è·å¾—ç½‘ç»œçš„é¢„æµ‹å€¼ã€‚é¢„æµ‹å€¼ out çš„ shape ä¸º[ğ‘, 10]ï¼Œåˆ†åˆ«ä»£è¡¨äº†æ ·æœ¬å±äºæ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡
    # 2. æˆ‘ä»¬æ ¹æ® tf.argmax å‡½æ•°é€‰å‡ºæ¦‚ç‡æœ€å¤§å€¼å‡ºç°çš„ç´¢å¼•å·ï¼Œä¹Ÿå³æ ·æœ¬æœ€æœ‰å¯èƒ½çš„ç±»åˆ«å·
    # 3. ç”±äºæˆ‘ä»¬çš„æ ‡æ³¨ y å·²ç»åœ¨é¢„å¤„ç†ä¸­å®Œæˆäº† one-hot ç¼–ç ï¼Œè¿™åœ¨æµ‹è¯•æ—¶å…¶å®æ˜¯ä¸éœ€è¦çš„ï¼Œå› æ­¤é€šè¿‡ tf.argmax å¯ä»¥å¾—åˆ°æ•°å­—ç¼–ç çš„æ ‡æ³¨ y
    # 4. é€šè¿‡ tf.equal å¯ä»¥æ¯”è¾ƒè¿™ä¸¤è€…çš„ç»“æœæ˜¯å¦ç›¸ç­‰
    # 5. å¹¶æ±‚å’Œæ¯”è¾ƒç»“æœä¸­æ‰€æœ‰ True(è½¬æ¢ä¸º 1)çš„æ•°é‡ï¼Œå³ä¸ºé¢„æµ‹æ­£ç¡®çš„æ•°é‡
    # 6. é¢„æµ‹æ­£ç¡®çš„æ•°é‡é™¤ä»¥æ€»æµ‹è¯•æ•°é‡å³å¯å¾—åˆ°å‡†ç¡®åº¦ï¼Œå¹¶æ‰“å°å‡ºæ¥
    pass
