## 第 6 章 神经网络

#### 6.2 全连接层

6.2.1 张量方式实现

在 TensorFlow 中，要实现全连接层，只需要定义好权值张量 𝑾 和偏置张量 𝒃，

并利用 TensorFlow 提供的批量矩阵相乘函数 tf.matmul()即可完成网络层的计算。

> @ 是矩阵乘法，\*是对应元素相乘

6.2.2 层方式实现

TensorFlow 中有更高层、使用更方便的层实现方式：

`layers.Dense(units, activation)。`

通过 layer.Dense 类，只需要指定输出节点数 Units 和激活函数类型 activation 即可。

- 可以通过类内部的成员名 kernel 和 bias 来获取权值张量 𝑾 和偏置张量 𝒃 对象
- 在优化参数时，需要获得网络的所有待优化的张量参数列表，可以通过类的 trainable_variables 来返回待优化参数列表
- 还有部分层包含了不参与梯度优化的张量，如后续介绍的 Batch Normalization 层，可以通过
  non_trainable_variables 成员返回所有不需要优化的参数列表。
  如果希望获得所有参数列表，可以通过类的 variables 返回所有内部张量列表
- 对于全连接层，内部张量都参与梯度优化，故 variables 返回的列表与 trainable_variables 相同。
- 利用网络层类对象进行前向计算时，只需要调用类的**call**方法即可，
    即写成 fc(x)方式便可，它会自动调用类的**call**方法，在**call**方法中会自动调用 call 方法


#### 6.3 神经网络

###### 6.3.1 张量方式实现
对于多层神经网络，以图 6.5 网络结构为例，需要分别定义各层的权值矩阵𝑾和偏置向量𝒃。

有多少个全连接层，则需要相应地定义数量相当的𝑾和𝒃，

并且每层的参数只能用于对应的层，不能混淆使用。

- 在计算时，只需要按照网络层的顺序，将上一层的输出作为当前层的输入即可，重复直至最后一层，并将输出层的输出作为网络的输出
- 最后一层是否需要添加激活函数通常视具体的任务而定，这里加不加都可以

在使用 TensorFlow 自动求导功能计算梯度时，

需要将前向计算过程放置在tf.GradientTape()环境中，

从而利用 GradientTape 对象的 gradient()方法自动求解参数的梯度，

并利用 optimizers 对象更新参数。


###### 6.3.2 层方式实现
对于常规的网络层，通过层方式实现起来更加简洁高效。
1. 首先新建各个网络层类，并指定各层的激活函数类型
2. 在前向计算时，依序通过各个网络层即可
3. 对于这种数据依次向前传播的网络，也可以通过 Sequential 容器封装成一个网络大类对象，调用大类的前向计算函数一次即可完成所有层的前向计算，使用起来更加方便
4. 前向计算时只需要调用一次网络大类对象，即可完成所有层的按序计算


#### 6.4 激活函数

- 可以通过 tf.nn.sigmoid 实现 Sigmoid 函数
- 可以通过 tf.nn.relu 实现 ReLU 函数
- LeakyReLU 函数=𝑝𝑥,𝑥 < 0,可以通过 tf.nn.leaky_relu 实现 LeakyReLU 函数,其中 alpha 参数代表𝑝
- 可以通过 tf.nn.tanh 实现 tanh 函数


#### 6.5 输出层设计

###### 6.5.3 [0,1]区间，和为 1
- 在 TensorFlow 中，可以通过 tf.nn.softmax 实现 Softmax 函数
- TensorFlow 中提供了一个统一的接口，将 Softmax 与交叉熵损失函数同时实现，同时也处理了数值不稳定的异常
- 函数式接口为tf.keras.losses.categorical_crossentropy(y_true, y_pred, from_logits=False)
- 为了数值计算稳定性，一般设置 from_logits 为 True，此时tf.keras.losses.categorical_crossentropy将在内部进行 Softmax 函数计算，所以不需要在模型中显式调用 Softmax 函数
- 除了函数式接口，也可以利用 losses.CategoricalCrossentropy(from_logits)类方式同时实现 Softmax 与交叉熵损失函数的计算，from_logits 参数的设置方式相同。

###### 6.5.4 [-1, 1]
如果希望输出值的范围分布在(−1,1)区间，可以简单地使用 tanh 激活函数



#### 6.6 误差计算
###### 6.6.1 均方差误差函数
- 均方差(Mean Squared Error，简称 MSE)误差函数把输出向量和真实向量映射到笛卡尔坐标系的两个点上，通过计算这两个点之间的欧式距离(准确地说是欧式距离的平方)来衡量两个向量之间的差距
- MSE 误差函数的值总是大于等于 0，当 MSE 函数达到最小值 0 时，输出等于真实标签，此时神经网络的参数达到最优状态
- 在 TensorFlow 中，可以通过函数方式或层方式实现 MSE 误差计算
- 特别要注意的是，MSE 函数返回的是每个样本的均方差，需要在样本维度上再次平均来获
得平均样本的均方差
- 也可以通过层方式实现，对应的类为 keras.losses.MeanSquaredError()，和其他层的类一
样


#### 6.8 汽车油耗预测实战
本节我们将利用全连接网络模型来完成汽车的效能指标 MPG(Mile Per Gallon，每加仑燃油英里数)的预测问题实战
###### 6.8.1 数据集
- 采用 Auto MPG 数据集，它记录了各种汽车效能指标与气缸数、重量、马力等其它因子的真实数据
- Auto MPG 数据集一共记录了 398 项数据，我们从 UCI 服务器下载并读取数据集到
DataFrame 对象中
- 原始表格中的数据可能含有空字段(缺失值)的数据项，需要清除这些记录项
- 由于 Origin 字段为类别类型数据，我们将其移除，并转换为新的 3 个字段：USA、Europe 和 Japan，分别代表是否来自此产地
- 按着 8:2 的比例切分数据集为训练集和测试集
- 将 MPG 字段移出为标签数据
- 统计训练集的各个字段数值的均值和标准差，并完成数据的标准化，通过 norm()函数实现
- 打印出训练集和测试集的大小
- 利用切分的训练集数据构建数据集对象
- 我们可以通过简单地统计数据集中各字段之间的两两分布来观察各个字段对 MPG 的影响

