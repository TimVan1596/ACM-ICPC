import tensorflow as tf
from sklearn import datasets, model_selection
import numpy as np

# å¯¼å…¥æ•°æ®
def load_data(N_SAMPLES=2000, TEST_SIZE=0.3):

    ###### 7.9.1 æ•°æ®é›†
    # - è¿™é‡Œé€šè¿‡ scikit-learn åº“æä¾›çš„ä¾¿æ·å·¥å…·ç”Ÿæˆ 2000 ä¸ªçº¿æ€§ä¸å¯åˆ†çš„ 2 åˆ†ç±»æ•°æ®é›†æ•°æ®çš„ç‰¹å¾é•¿åº¦ä¸º 2
    # - æ‰€æœ‰çš„çº¢è‰²ç‚¹ä¸ºä¸€ç±»ï¼Œæ‰€æœ‰çš„è“è‰²ç‚¹ä¸ºä¸€ç±»
    # - å¯ä»¥çœ‹åˆ°æ¯ä¸ªç±»åˆ«æ•°æ®çš„åˆ†å¸ƒå‘ˆæœˆç‰™çŠ¶ï¼Œå¹¶ä¸”æ˜¯æ˜¯çº¿æ€§ä¸å¯åˆ†çš„ï¼Œæ— æ³•ç”¨çº¿æ€§ç½‘ç»œè·å¾—è¾ƒå¥½æ•ˆæœã€‚
    # - æˆ‘ä»¬æŒ‰ç€7: 3æ¯”ä¾‹åˆ‡åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œå…¶ä¸­2000 âˆ™ 0 3 = 600ä¸ªæ ·æœ¬ç‚¹ç”¨äºæµ‹è¯•ï¼Œä¸å‚ä¸è®­ç»ƒï¼Œå‰©ä¸‹çš„ 1400 ä¸ªç‚¹ç”¨äºç½‘ç»œçš„è®­ç»ƒ

    # 1. æ•°æ®é›†çš„é‡‡é›†ç›´æ¥ä½¿ç”¨ scikit-learn æä¾›çš„ make_moons å‡½æ•°ç”Ÿæˆï¼Œè®¾ç½®é‡‡æ ·ç‚¹æ•°å’Œåˆ‡å‰²æ¯”ç‡

    # åˆ©ç”¨å·¥å…·å‡½æ•°ç›´æ¥ç”Ÿæˆæ•°æ®é›†
    # make_moonsæ˜¯å‡½æ•°ç”¨æ¥ç”Ÿæˆæ•°æ®é›†
    # ç”»ä¸¤ä¸ªç›¸äº’äº¤é”™çš„åŠåœ†ã€‚
    X, y = datasets.make_moons(n_samples=N_SAMPLES, noise=0.2, random_state=50)

    print(f"-- X.shape={X.shape}, y.shape={y.shape}")

    # 2. å¯ä»¥é€šè¿‡å¦‚ä¸‹å¯è§†åŒ–ä»£ç ç»˜åˆ¶æ•°æ®é›†çš„åˆ†å¸ƒ
    # è°ƒç”¨ make_plot å‡½æ•°ç»˜åˆ¶æ•°æ®çš„åˆ†å¸ƒï¼Œå…¶ä¸­ X ä¸º 2D åæ ‡ï¼Œy ä¸ºæ ‡ç­¾
    make_plot(X, y, plot_name="åˆ†ç±»æ•°æ®é›†çš„å¯è§†åŒ–")
    # å°† 2000 ä¸ªç‚¹æŒ‰ç€ 7:3 åˆ†å‰²ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†
    # model_selection.train_test_split
    # å°†æ•°ç»„æˆ–çŸ©é˜µåˆ†å‰²æˆéšæœºåºåˆ—å’Œæµ‹è¯•å­é›†ã€‚
    X_train, X_test, y_train, y_test = model_selection.train_test_split(
        X, y, test_size=TEST_SIZE, random_state=42
    )
    return X_train, X_test, y_train, y_test


# ç»˜åˆ¶æ•°æ®é›†çš„åˆ†å¸ƒï¼ŒX ä¸º 2D åæ ‡ï¼Œy ä¸ºæ•°æ®ç‚¹çš„æ ‡ç­¾
def make_plot(
    X, y, plot_name, file_name=None, XX=None, YY=None, preds=None, dark=False
):
    from matplotlib import pyplot as plt
    import seaborn as sns

    # matplotlibå…¶å®æ˜¯ä¸æ”¯æŒæ˜¾ç¤ºä¸­æ–‡çš„ æ˜¾ç¤ºä¸­æ–‡éœ€è¦ä¸€è¡Œä»£ç è®¾ç½®å­—ä½“
    # è§£å†³åæ ‡è½´è´Ÿæ•°çš„è´Ÿå·æ˜¾ç¤ºé—®é¢˜
    plt.rcParams["axes.unicode_minus"] = False

    if dark:
        plt.style.use("dark_background")
    else:
        # sns = seaborn
        # seabornæ˜¯pythonä¸­çš„ä¸€ä¸ªå¯è§†åŒ–åº“ï¼Œæ˜¯å¯¹matplotlibè¿›è¡ŒäºŒæ¬¡å°è£…è€Œæˆ
        sns.set_style("whitegrid")
    plt.figure(figsize=(8, 6))
    axes = plt.gca()
    # Matplotlib.axes.Axes.set()
    # è®¾ç½®xlabelï¼Œylabel ï¼Œxlim ï¼Œylim å’Œ titleç­‰
    axes.set(xlabel="$x_1$", ylabel="$x_2$")
    plt.title(plot_name, fontsize=15, fontproperties="SimHei")
    # å›¾åƒçš„è¾¹ç•Œä½ç½®è°ƒæ•´
    plt.subplots_adjust(left=0.20)
    plt.subplots_adjust(right=0.80)
    if XX is not None and YY is not None and preds is not None:
        # contourå’Œcontourféƒ½æ˜¯ç”»ä¸‰ç»´ç­‰é«˜çº¿å›¾çš„ï¼Œä¸åŒç‚¹åœ¨äºcontourfä¼šå¯¹ç­‰é«˜çº¿é—´çš„åŒºåŸŸè¿›è¡Œå¡«å……
        # cm.Spectral = å…‰è°±é¢œè‰²å›¾
        plt.contourf(XX, YY, preds.reshape(XX.shape), 25, alpha=1, cmap=cm.Spectral)
        plt.contour(
            XX,
            YY,
            preds.reshape(XX.shape),
            levels=[0.5],
            cmap="Greys",
            vmin=0,
            vmax=0.6,
        )
    # ç»˜åˆ¶æ•£ç‚¹å›¾ï¼Œæ ¹æ®æ ‡ç­¾åŒºåˆ†é¢œè‰²
    plt.scatter(
        X[:, 0], X[:, 1], c=y.ravel(), s=40, cmap=plt.cm.Spectral, edgecolors="none"
    )
    # SVGæ˜¯ä¸€ç§å›¾å½¢æ–‡ä»¶æ ¼å¼ï¼Œå®ƒçš„è‹±æ–‡å…¨ç§°ä¸ºScalable Vector Graphicsï¼Œæ„æ€ä¸ºå¯ç¼©æ”¾çš„çŸ¢é‡å›¾å½¢
    plt.savefig("dataset.jpg")
    plt.show()
    plt.close()


if __name__ == "__main__":
    # #### 7.9 åå‘ä¼ æ’­ç®—æ³•å®æˆ˜
    # - æˆ‘ä»¬å°†å®ç°ä¸€ä¸ª 4 å±‚çš„å…¨è¿æ¥ç½‘ç»œï¼Œæ¥å®ŒæˆäºŒåˆ†ç±»ä»»åŠ¡ã€‚
    # - ç½‘ç»œè¾“å…¥èŠ‚ç‚¹æ•°ä¸º 2ï¼Œéšè—å±‚çš„èŠ‚ç‚¹æ•°è®¾è®¡ä¸ºï¼š25ã€50å’Œ25
    # - è¾“å‡ºå±‚ä¸¤ä¸ªèŠ‚ç‚¹ï¼Œåˆ†åˆ«è¡¨ç¤ºå±äºç±»åˆ« 1 çš„æ¦‚ç‡å’Œç±»åˆ« 2çš„æ¦‚ç‡
    # - ç›´æ¥åˆ©ç”¨å‡æ–¹è¯¯å·®å‡½æ•°è®¡ç®—ä¸ One-hot ç¼–ç çš„çœŸå®æ ‡ç­¾ä¹‹é—´çš„è¯¯å·®
    # - æ‰€æœ‰çš„ç½‘ç»œæ¿€æ´»å‡½æ•°å…¨éƒ¨é‡‡ç”¨ Sigmoid å‡½æ•°

    # 1. å¯¼å…¥æ•°æ®
    # é‡‡æ ·ç‚¹æ•°
    N_SAMPLES = 2000
    # æµ‹è¯•æ•°é‡æ¯”ç‡
    TEST_SIZE = 0.3
    X_train, X_test, y_train, y_test = load_data(
        N_SAMPLES=N_SAMPLES, TEST_SIZE=TEST_SIZE
    )

    # ###### 7.9.2 ç½‘ç»œå±‚
    # 1. é€šè¿‡æ–°å»ºç±» Layer å®ç°ä¸€ä¸ªç½‘ç»œå±‚
    # - é€šè¿‡æ–°å»ºç±» Layer å®ç°ä¸€ä¸ªç½‘ç»œå±‚ï¼Œéœ€è¦ä¼ å…¥ç½‘ç»œå±‚çš„è¾“å…¥èŠ‚ç‚¹æ•°ã€è¾“å‡ºèŠ‚ç‚¹æ•°ã€æ¿€æ´»å‡½æ•°ç±»å‹ç­‰å‚æ•°ï¼Œ
    # - æƒå€¼ weights å’Œåç½®å¼ é‡ bias åœ¨åˆå§‹åŒ–æ—¶æ ¹æ®è¾“å…¥ã€è¾“å‡ºèŠ‚ç‚¹æ•°è‡ªåŠ¨ç”Ÿæˆå¹¶åˆå§‹åŒ–ã€‚
    class Layer:
        # 1.å…¨è¿æ¥ç½‘ç»œå±‚
        def __init__(
            self, n_input, n_neurons, activation=None, weights=None, bias=None
        ):
            """
            :param int n_input: è¾“å…¥èŠ‚ç‚¹æ•°
            :param int n_neurons: è¾“å‡ºèŠ‚ç‚¹æ•°
            :param str activation: æ¿€æ´»å‡½æ•°ç±»å‹
            :param weights: æƒå€¼å¼ é‡ï¼Œé»˜è®¤ç±»å†…éƒ¨ç”Ÿæˆ
            :param bias: åç½®ï¼Œé»˜è®¤ç±»å†…éƒ¨ç”Ÿæˆ
            """
            # é€šè¿‡æ­£æ€åˆ†å¸ƒåˆå§‹åŒ–ç½‘ç»œæƒå€¼ï¼Œåˆå§‹åŒ–éå¸¸é‡è¦ï¼Œä¸åˆé€‚çš„åˆå§‹åŒ–å°†å¯¼è‡´ç½‘ç»œä¸æ”¶æ•›
            self.weights = (
                weights
                if weights is not None
                else np.random.randn(n_input, n_neurons) * np.sqrt(1 / n_neurons)
            )
            self.bias = bias if bias is not None else np.random.rand(n_neurons) * 0.1
            # æ¿€æ´»å‡½æ•°ç±»å‹ï¼Œå¦‚â€™sigmoidâ€™
            self.activation = activation
            # æ¿€æ´»å‡½æ•°çš„è¾“å‡ºå€¼ o
            self.last_activation = None
            # ç”¨äºè®¡ç®—å½“å‰å±‚çš„ delta å˜é‡çš„ä¸­é—´å˜é‡
            self.error = None
            # è®°å½•å½“å‰å±‚çš„ delta å˜é‡ï¼Œç”¨äºè®¡ç®—æ¢¯åº¦
            self.delta = None
            pass

        # 2.ç½‘ç»œå±‚çš„å‰å‘ä¼ æ’­å‡½æ•°å®ç°å¦‚ä¸‹ï¼Œå…¶ä¸­ last_activation å˜é‡ç”¨äºä¿å­˜å½“å‰å±‚çš„è¾“å‡ºå€¼
        def activate(self, x):
            # å‰å‘ä¼ æ’­å‡½æ•°
            r = np.dot(x, self.weights) + self.bias  # X@W+b
            # é€šè¿‡æ¿€æ´»å‡½æ•°ï¼Œå¾—åˆ°å…¨è¿æ¥å±‚çš„è¾“å‡º o
            self.last_activation = self._apply_activation(r)
            return self.last_activation

        # 3. ä¸Šè¿°ä»£ç ä¸­çš„ self._apply_activation å‡½æ•°å®ç°äº†ä¸åŒç±»å‹çš„æ¿€æ´»å‡½æ•°çš„å‰å‘è®¡ç®—è¿‡ç¨‹ï¼Œ
        # å°½ç®¡æ­¤å¤„æˆ‘ä»¬åªä½¿ç”¨ Sigmoid æ¿€æ´»å‡½æ•°ä¸€ç§
        def _apply_activation(self, r):
            # è®¡ç®—æ¿€æ´»å‡½æ•°çš„è¾“å‡º
            if self.activation is None:
                return r  # æ— æ¿€æ´»å‡½æ•°ï¼Œç›´æ¥è¿”å›
            # ReLU æ¿€æ´»å‡½æ•°
            elif self.activation == "relu":
                return np.maximum(r, 0)
            # tanh æ¿€æ´»å‡½æ•°
            elif self.activation == "tanh":
                return np.tanh(r)
            # sigmoid æ¿€æ´»å‡½æ•°
            elif self.activation == "sigmoid":
                return 1 / (1 + np.exp(-r))
            return r

        # 4. é’ˆå¯¹äºä¸åŒç±»å‹çš„æ¿€æ´»å‡½æ•°ï¼Œå®ƒä»¬çš„å¯¼æ•°è®¡ç®—å®ç°å¦‚ä¸‹
        def apply_activation_derivative(self, r):
            # è®¡ç®—æ¿€æ´»å‡½æ•°çš„å¯¼æ•°
            # æ— æ¿€æ´»å‡½æ•°ï¼Œå¯¼æ•°ä¸º 1
            if self.activation is None:
                return np.ones_like(r)
            # ReLU å‡½æ•°çš„å¯¼æ•°å®ç°
            elif self.activation == "relu":
                grad = np.array(r, copy=True)
                grad[r > 0] = 1.0
                grad[r <= 0] = 0.0
                return grad
            # tanh å‡½æ•°çš„å¯¼æ•°å®ç°
            elif self.activation == "tanh":
                return 1 - r**2
            # Sigmoid å‡½æ•°çš„å¯¼æ•°å®ç°
            # 5. å¯ä»¥çœ‹åˆ°ï¼ŒSigmoid å‡½æ•°çš„å¯¼æ•°å®ç°ä¸ºğ‘Ÿ (1 âˆ’ ğ‘Ÿ)ï¼Œå…¶ä¸­ğ‘Ÿå³ä¸ºğœ(ğ‘§)
            elif self.activation == "sigmoid":
                return r * (1 - r)
            return r

    pass
