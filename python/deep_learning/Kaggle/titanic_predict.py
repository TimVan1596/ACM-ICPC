import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.python.keras import activations
import matplotlib.pyplot as plt
from tensorflow.keras import regularizers
import datetime

# æ˜¾ç¤ºè®­ç»ƒæƒ…å†µ


def plot_history(history):
    # histotyçš„è¿”å›å€¼
    # ä¸€ä¸ªå†å²å¯¹è±¡ã€‚å®ƒçš„ History.history å±æ€§æ˜¯è¿ç»­ epoch çš„è®­ç»ƒæŸå¤±å€¼å’ŒæŒ‡æ ‡å€¼çš„è®°å½•ï¼Œä»¥åŠéªŒè¯æŸå¤±å€¼å’ŒéªŒè¯æŒ‡æ ‡å€¼ï¼ˆå¦‚æœé€‚ç”¨ï¼‰ã€‚
    # history.historyï¼šlossã€accuracyã€val lossã€val accuracy
    hist = pd.DataFrame(history.history)
    hist["epoch"] = history.epoch

    plt.figure()
    plt.xlabel("Num of Epochs")
    plt.ylabel("value")
    plt.plot(hist["epoch"], hist["accuracy"], label="accuracy")
    plt.plot(hist["epoch"], hist["val_accuracy"], label="val_accuracy")
    plt.ylim([0, 1])
    plt.legend()
    plt.show()


# å¯¼å…¥æ•°æ®
def load_data(path_url, test_path_url):
    raw_train_dataset = pd.read_csv(path_url)
    raw_test_dataset = pd.read_csv(test_path_url)
    return raw_train_dataset, raw_test_dataset


# æ•°æ®é¢„å¤„ç†çš„åŸºç¡€æ–¹æ³•
def preprocess(raw_dataset, features, train=True):
    """ç”¨äºpredictçš„æ•°æ®é¢„å¤„ç†
    Args:
        input: dataset = pandas.DataFrameå¯¹è±¡
    """
    # ä»¥ä¸­ä½æ•°æ¥æ›¿ä»£
    if "Age" in features:
        raw_dataset["Age"].fillna(raw_dataset["Age"].median(), inplace=True)
    raw_dataset["Fare"].fillna(raw_dataset["Fare"].median(), inplace=True)
    raw_dataset["Embarked"].fillna(raw_dataset["Fare"].median(), inplace=True)
    dataset = raw_dataset[features]
    dataset = dataset.copy()

    # ç”±äº embarked=ç™»èˆ¹æ¸¯å£, Port of Embarkation	C = Cherbourg, Q = Queenstown, S = Southampton

    Embarked = dataset.pop("Embarked")

    # æ ¹æ® embarked åˆ—æ¥å†™å…¥æ–°çš„ 3 ä¸ªåˆ—
    dataset["S"] = (Embarked == "S") * 1.0
    dataset["C"] = (Embarked == "C") * 1.0
    dataset["Q"] = (Embarked == "Q") * 1.0

    # æ ¹æ® sex åˆ—æ¥å†™å…¥æ–°çš„ 2 ä¸ªåˆ—
    Sex = dataset.pop("Sex")
    dataset["Male"] = (Sex == "male") * 1.0
    dataset["Female"] = (Sex == "female") * 1.0

    dataset_withoutna = dataset
    if train:
        labels = dataset_withoutna["Survived"]
        dataset_withoutna.pop("PassengerId")
        dataset_withoutna.pop("Survived")
        # æ ‡å‡†åŒ–
        train_stats = dataset_withoutna.describe()
        train_stats = train_stats.transpose()
        normed_train_data = (dataset_withoutna - train_stats["mean"]) / train_stats[
            "std"
        ]
        return np.array(normed_train_data), np.array(labels)
    else:
        labels = dataset.pop("PassengerId")
        dataset.fillna(0, inplace=True)
        test_stats = dataset.describe()
        test_stats = test_stats.transpose()
        normed_test_data = (dataset - test_stats["mean"]) / test_stats["std"]
        return np.array(normed_test_data), np.array(labels)


# è®­ç»ƒ
def train(train_dataset, labels, epochs=120, batch_size=512, is_plot=False):
    model = tf.keras.Sequential(
        [
            # 1. input_shape = è¾“å…¥å½¢çŠ¶
            # ND å¼ é‡çš„å½¢çŠ¶ï¼š. æœ€å¸¸è§çš„æƒ…å†µæ˜¯å¸¦æœ‰ shape çš„ 2D è¾“å…¥ã€‚
            # 2. kernel_regularizer = åº”ç”¨äºkernelæƒé‡çŸ©é˜µçš„æ­£åˆ™åŒ–å‡½æ•°ã€‚
            # ğ¿2æ­£åˆ™åŒ–ï¼šèŒƒæ•°çš„å¹³æ–¹
            tf.keras.layers.Dense(
                64,
                activation="relu",
                input_shape=(train_dataset.shape[1],),
                kernel_regularizer=regularizers.l2(0.001),
            ),
            tf.keras.layers.Dense(
                32, activation="relu", kernel_regularizer=regularizers.l2(0.001)
            ),
            tf.keras.layers.Dense(16, activation="relu"),
            tf.keras.layers.Dense(1, name="prediction"),
        ]
    )

    # åœ¨ Keras ä¸­æä¾›äº† compile()å’Œ fit()å‡½æ•°æ–¹ä¾¿å®ç°é€»è¾‘ã€‚
    # compileï¼šé¦–å…ˆé€šè¿‡compile å‡½æ•°æŒ‡å®šç½‘ç»œä½¿ç”¨çš„ä¼˜åŒ–å™¨å¯¹è±¡ã€æŸå¤±å‡½æ•°ç±»å‹ï¼Œè¯„ä»·æŒ‡æ ‡ç­‰è®¾å®šï¼Œè¿™ä¸€æ­¥ç§°ä¸ºè£…é…
    # fitï¼š æ¨¡å‹è£…é…å®Œæˆåï¼Œå³å¯é€šè¿‡ fit()å‡½æ•°é€å…¥å¾…è®­ç»ƒçš„æ•°æ®é›†å’ŒéªŒè¯ç”¨çš„æ•°æ®é›†
    model.compile(
        # Adamçš„å­¦ä¹ å¾‹é»˜è®¤ä¸º0.001
        optimizer=tf.keras.optimizers.Adam(),
        # BinaryCrossentropy:è®¡ç®—çœŸå®æ ‡ç­¾å’Œé¢„æµ‹æ ‡ç­¾ä¹‹é—´çš„äº¤å‰ç†µæŸå¤±
        loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
        # è®¾ç½®æµ‹é‡æŒ‡æ ‡ä¸ºå‡†ç¡®ç‡
        metrics=["accuracy"],
    )

    # æ¨¡å‹è£…é…å®Œæˆåï¼Œå³å¯é€šè¿‡ fit()å‡½æ•°é€å…¥å¾…è®­ç»ƒçš„æ•°æ®é›†å’ŒéªŒè¯ç”¨çš„æ•°æ®é›†ï¼Œè¿™ä¸€æ­¥ç§°ä¸ºæ¨¡å‹è®­ç»ƒ
    # verbose = 'auto'ã€0ã€1 æˆ– 2 è¯¦ç»†æ¨¡å¼ã€‚
    # 0 = é™éŸ³ï¼Œ1 = è¿›åº¦æ¡ï¼Œ2 = æ¯ä¸ª epoch ä¸€è¡Œã€‚'auto' åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹é»˜è®¤ä¸º 1
    history = model.fit(
        x=train_dataset,
        y=labels,
        epochs=epochs,
        validation_split=0.3,
        batch_size=batch_size,
        verbose="auto",
        # callbacks=[early_stop]
    )

    # æ˜¾ç¤ºè®­ç»ƒæƒ…å†µ
    if is_plot:
        plot_history(history)

    # å¯ä»¥é€šè¿‡ Model.evaluate(db)å¾ªç¯æµ‹è¯•å®Œ db æ•°æ®é›†ä¸Šæ‰€æœ‰æ ·æœ¬
    loss, accuracy = model.evaluate(train_dataset, labels, verbose=2)
    print("Accuracy:", accuracy)

    return model


# çœŸå®é¢„æµ‹å¹¶è¾“å‡ºcsv
def predict_out(model, csv_path):
    # model.evaluate å’Œ model.predict çš„åŒºåˆ«
    # https://blog.csdn.net/DoReAGON/article/details/88552348
    # ä¸¤è€…å·®å¼‚ï¼š
    # 1
    # è¾“å…¥è¾“å‡ºä¸åŒ
    # model.evaluateè¾“å…¥æ•°æ®(data)å’Œé‡‘æ ‡å‡†(label),ç„¶åå°†é¢„æµ‹ç»“æœä¸é‡‘æ ‡å‡†ç›¸æ¯”è¾ƒ,å¾—åˆ°ä¸¤è€…è¯¯å·®å¹¶è¾“å‡º.
    # model.predictè¾“å…¥æ•°æ®(data),è¾“å‡ºé¢„æµ‹ç»“æœ
    # 2
    # æ˜¯å¦éœ€è¦çœŸå®æ ‡ç­¾(é‡‘æ ‡å‡†)
    # model.evaluateéœ€è¦,å› ä¸ºéœ€è¦æ¯”è¾ƒé¢„æµ‹ç»“æœä¸çœŸå®æ ‡ç­¾çš„è¯¯å·®
    # model.predictä¸éœ€è¦,åªæ˜¯å•çº¯è¾“å‡ºé¢„æµ‹ç»“æœ,å…¨ç¨‹ä¸éœ€è¦é‡‘æ ‡å‡†çš„å‚ä¸.
    predictions = model.predict(test_dataset)
    # é€šè¿‡astype()æ–¹æ³•å¯ä»¥å¼ºåˆ¶è½¬æ¢æ•°æ®çš„ç±»å‹ã€‚
    predictions = (tf.sigmoid(predictions).numpy().flatten() > 0.5).astype(int)
    print(predictions.shape, predictions)
    # è¾“å‡ºç»“æœ
    output = pd.DataFrame(
        {"PassengerId": passenger_id, "Survived": predictions})
    # index=False ä¸ä¿å­˜è¡Œç´¢å¼•,index=æ˜¯å¦ä¿ç•™è¡Œç´¢å¼•
    output.to_csv(csv_path, index=False)
    print(f"æ‚¨çš„æäº¤æ–‡ä»¶ä¿å­˜æˆåŠŸ! ä½ç½®åœ¨{csv_path}")
    return predictions


# è·å–å¹´æœˆæ—¥æ—¶åˆ†ç§’
def get_time():
    return datetime.datetime.now().strftime("%Y%m%d%H%M")


# #### Titanic - Machine Learning from Disaster

if __name__ == "__main__":

    # 1. å¯¼å…¥æ•°æ®
    path_url = r"kaggle\titanic\train.csv"
    test_path_url = r"kaggle\titanic\test.csv"

    raw_train_dataset, raw_test_dataset = load_data(path_url, test_path_url)

    # 2. æ•°æ®é¢„å¤„ç†
    features_test = [
        "PassengerId",
        "Pclass",
        "Sex",
        "Fare",
        "Age",
        "SibSp",
        "Parch",
        "Embarked",
    ]
    features_train = features_test + ["Survived"]

    # è·å–é¢„å¤„ç†åçš„è®­ç»ƒé›†å’Œæ ‡ç­¾
    train_dataset, labels = preprocess(raw_train_dataset, features_train)

    # 3. è®­ç»ƒ
    model = train(train_dataset, labels, epochs=256, is_plot=True)

    # è·å–é¢„å¤„ç†åçš„æµ‹è¯•é›†å’Œåºå·
    test_dataset, passenger_id = preprocess(
        raw_test_dataset, features_test, train=False
    )

    # è¾“å‡ºé¢„æµ‹ç»“æœ
    csv_path = f"./submission_{get_time()}.csv"
    prediction = predict_out(model, csv_path)

    # éªŒè¯ä¸åŸå§‹æ•°æ®raw_test_dataseté•¿åº¦æ˜¯å¦ä¸€è‡´
    if prediction.shape[0] == raw_test_dataset.shape[0]:
        print(f"--é¢„æµ‹é•¿åº¦={prediction.shape[0]}æ ¡éªŒé€šè¿‡ âˆš")
    else:
        print(
            f"--é¢„æµ‹é•¿åº¦ä¸raw_test_dataseté•¿åº¦ä¸ä¸€è‡´ Ã—,prediction.shape={prediction.shape},raw_test_dataset.shape={raw_test_dataset.shape}"
        )
